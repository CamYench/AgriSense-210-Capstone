{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import rasterio\n",
    "from skimage.transform import resize\n",
    "from skimage.transform import rotate\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tqdm import tqdm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from datetime import timedelta\n",
    "from skimage.draw import polygon\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "from utils import process_yield_data\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Yield Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Volume (Pounds)  Cumulative Volumne (Pounds)  Pounds/Acre\n",
      "Date                                                                 \n",
      "2012-01-02          23400.0                      23400.0          2.0\n",
      "2012-01-03          26064.0                      49464.0          3.0\n",
      "2012-01-04          32382.0                      81846.0          3.0\n",
      "2012-01-05          69804.0                     151650.0          7.0\n",
      "2012-01-06          18000.0                     169650.0          2.0\n",
      "\n",
      "Number of Yield Data Points:  3970\n",
      "\n",
      "Column Names: Index(['Volume (Pounds)', 'Cumulative Volumne (Pounds)', 'Pounds/Acre'], dtype='object')\n",
      "Number of Yield Data Points: 2879\n",
      "Yield data with time features:\n",
      "            Volume (Pounds)  Cumulative Volumne (Pounds)  Pounds/Acre  \\\n",
      "Date                                                                    \n",
      "2012-03-04         525753.0                    1785843.0    18.333333   \n",
      "2012-03-11        2949534.0                    4735377.0    51.666667   \n",
      "2012-03-18        4772268.0                    9507645.0    83.500000   \n",
      "2012-03-25        3142314.0                   12649959.0    55.000000   \n",
      "2012-04-01        6271398.0                   18921357.0    93.857143   \n",
      "\n",
      "            month_sin     month_cos  day_of_year_sin  day_of_year_cos  \n",
      "Date                                                                   \n",
      "2012-03-04   1.000000  6.123234e-17         0.891981         0.452072  \n",
      "2012-03-11   1.000000  6.123234e-17         0.939856         0.341571  \n",
      "2012-03-18   1.000000  6.123234e-17         0.974100         0.226116  \n",
      "2012-03-25   1.000000  6.123234e-17         0.994218         0.107381  \n",
      "2012-04-01   0.866025 -5.000000e-01         0.999917        -0.012910  \n"
     ]
    }
   ],
   "source": [
    "YIELD_DATA_PATH = Path(\"./combined_yield_data.csv\")\n",
    "yield_data_weekly = process_yield_data(YIELD_DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "target_shape = (512, 512)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Old Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNFeatureExtractor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNFeatureExtractor, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.conv4 = nn.Conv2d(128, 256, 3, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(256)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.flattened_size = self._get_conv_output((1, *target_shape))\n",
    "        self.fc1 = nn.Linear(self.flattened_size, 512)\n",
    "\n",
    "    def _get_conv_output(self, shape):\n",
    "        x = torch.rand(1, *shape)\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
    "        x = self.pool(F.relu(self.bn4(self.conv4(x))))\n",
    "        n_size = x.view(1, -1).size(1)\n",
    "        return n_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
    "        x = self.pool(F.relu(self.bn4(self.conv4(x))))\n",
    "        x = self.dropout(x)\n",
    "        x = x.view(-1, self.flattened_size)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return x\n",
    "    \n",
    "class HybridModel(nn.Module):\n",
    "    def __init__(self, cnn_feature_extractor, lstm_hidden_size=64, lstm_layers=1):\n",
    "        super(HybridModel, self).__init__()\n",
    "        self.cnn = cnn_feature_extractor\n",
    "        self.lstm = nn.LSTM(input_size=512, hidden_size=lstm_hidden_size, num_layers=lstm_layers, batch_first=True)\n",
    "        self.fc1 = nn.Linear(lstm_hidden_size + 4, 64)\n",
    "        self.fc2 = nn.Linear(64, target_shape[0] * target_shape[1])  # Predict a value per pixel\n",
    "        self.target_shape = target_shape\n",
    "\n",
    "    def forward(self, x, time_features):\n",
    "        batch_size, time_steps, C, H, W = x.size()\n",
    "        c_in = x.view(batch_size * time_steps, C, H, W)\n",
    "        c_out = self.cnn(c_in)\n",
    "        r_in = c_out.view(batch_size, time_steps, -1)\n",
    "        r_out, (h_n, c_n) = self.lstm(r_in)\n",
    "        r_out = r_out[:, -1, :]\n",
    "        x = torch.cat((r_out, time_features), dim=1)  # Concatenate LSTM output with time features\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        x = x.view(batch_size, *self.target_shape)  # Reshape to the target shape\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "        nn.init.kaiming_normal_(m.weight)\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "\n",
    "# # Instantiate model with weight decay regularization\n",
    "# cnn_feature_extractor = CNNFeatureExtractor()\n",
    "# model = HybridModel(cnn_feature_extractor)\n",
    "# model.apply(weights_init)\n",
    "# model.to(device)\n",
    "\n",
    "batch_size = 16\n",
    "epochs = 50\n",
    "\n",
    "# criterion = nn.MSELoss()\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.01)\n",
    "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inference_utils import (\n",
    "    preprocess_image,\n",
    "    compute_mean_std,\n",
    "    load_evi_data_and_prepare_features,\n",
    "    find_closest_date,\n",
    "    find_closest_date_in_df,\n",
    "    mask_evi_data,\n",
    "    predict,\n",
    "    predict_weekly_yield,\n",
    "    augment_image,\n",
    "    prepare_dataset,\n",
    "    train_and_evaluate,\n",
    "    sync_evi_yield_data\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed file 1/83 in 4.595581s\n",
      "Processed file 2/83 in 4.526565s\n",
      "Processed file 3/83 in 3.917106s\n",
      "Processed file 4/83 in 3.764339s\n",
      "Processed file 5/83 in 3.676140s\n",
      "Processed file 6/83 in 4.567551s\n",
      "Processed file 7/83 in 3.621552s\n",
      "Processed file 8/83 in 3.832261s\n",
      "Processed file 9/83 in 4.168375s\n",
      "Processed file 10/83 in 4.570174s\n",
      "Processed file 11/83 in 4.064863s\n",
      "Processed file 12/83 in 3.764896s\n",
      "Processed file 13/83 in 4.694772s\n",
      "Processed file 14/83 in 4.377803s\n",
      "Processed file 15/83 in 4.709882s\n",
      "Processed file 16/83 in 3.200550s\n",
      "Processed file 17/83 in 3.936213s\n",
      "Processed file 18/83 in 3.715976s\n",
      "Processed file 19/83 in 4.364548s\n",
      "Processed file 20/83 in 4.520379s\n",
      "Processed file 21/83 in 4.114959s\n",
      "Processed file 22/83 in 3.151981s\n",
      "Processed file 23/83 in 3.616206s\n",
      "Processed file 24/83 in 4.097888s\n",
      "Processed file 25/83 in 4.182319s\n",
      "Processed file 26/83 in 3.813179s\n",
      "Processed file 27/83 in 3.882825s\n",
      "Processed file 28/83 in 4.213806s\n",
      "Processed file 29/83 in 4.289558s\n",
      "Processed file 30/83 in 3.577581s\n",
      "Processed file 31/83 in 3.983253s\n",
      "Processed file 32/83 in 3.615749s\n",
      "Processed file 33/83 in 3.627716s\n",
      "Processed file 34/83 in 3.907350s\n",
      "Processed file 35/83 in 4.233271s\n",
      "Processed file 36/83 in 3.951328s\n",
      "Processed file 37/83 in 3.994078s\n",
      "Processed file 38/83 in 4.240645s\n",
      "Processed file 39/83 in 3.867372s\n",
      "Processed file 40/83 in 4.352584s\n",
      "Processed file 41/83 in 3.311715s\n",
      "Processed file 42/83 in 4.031415s\n",
      "Processed file 43/83 in 3.450300s\n",
      "Processed file 44/83 in 3.804492s\n",
      "Processed file 45/83 in 4.787008s\n",
      "Processed file 46/83 in 3.141854s\n",
      "Processed file 47/83 in 4.724723s\n",
      "Processed file 48/83 in 4.137484s\n",
      "Processed file 49/83 in 3.868221s\n",
      "Processed file 50/83 in 4.661652s\n",
      "Processed file 51/83 in 3.710038s\n",
      "Processed file 52/83 in 4.306405s\n",
      "Processed file 53/83 in 4.218897s\n",
      "Processed file 54/83 in 5.068501s\n",
      "Processed file 55/83 in 2.854151s\n",
      "Processed file 56/83 in 4.060981s\n",
      "Processed file 57/83 in 3.905297s\n",
      "Processed file 58/83 in 3.586498s\n",
      "Processed file 59/83 in 3.753990s\n",
      "Processed file 60/83 in 3.991899s\n",
      "Processed file 61/83 in 3.877591s\n",
      "Processed file 62/83 in 3.454317s\n",
      "Processed file 63/83 in 3.397349s\n",
      "Processed file 64/83 in 4.323048s\n",
      "Processed file 65/83 in 3.694734s\n",
      "Processed file 66/83 in 3.665407s\n",
      "Processed file 67/83 in 3.558331s\n",
      "Processed file 68/83 in 3.711551s\n",
      "Processed file 69/83 in 3.832361s\n",
      "Processed file 70/83 in 4.074966s\n",
      "Processed file 71/83 in 4.165006s\n",
      "Processed file 72/83 in 4.066938s\n",
      "Processed file 73/83 in 4.037999s\n",
      "Processed file 74/83 in 3.728307s\n",
      "Processed file 75/83 in 4.542453s\n",
      "Processed file 76/83 in 4.052765s\n",
      "Processed file 77/83 in 3.786244s\n",
      "Processed file 78/83 in 4.323349s\n",
      "Processed file 79/83 in 4.122608s\n",
      "Processed file 80/83 in 4.898066s\n",
      "Processed file 81/83 in 5.078701s\n",
      "Processed file 82/83 in 3.812632s\n",
      "Processed file 83/83 in 3.839378s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load EVI data and prepare time features\n",
    "evi_data_dir = \"./landsat_evi_monterey_masked\"\n",
    "train_loader, val_loader, mean, std = prepare_dataset(evi_data_dir, yield_data_weekly, target_shape, augment=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation (Cross Validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# this needs to be fixed. The loaders below are not using the time series split folds for cross-validation\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "mse_scores = []\n",
    "rmse_scores = []\n",
    "mae_scores = []\n",
    "r2_scores = []\n",
    "\n",
    "epochs = 50\n",
    "\n",
    "for fold, (train_index, val_index) in enumerate(tscv.split(yield_data_weekly)):\n",
    "    print(f\"Fold {fold + 1}\")\n",
    "    print(f\"       Train Index = {train_index[0]}, ..., {train_index[-1]} len={len(train_index)}\")\n",
    "    print(f\"       Valid Index = {val_index[0]}, ..., {val_index[-1]} len={len(val_index)}\")\n",
    "\n",
    "\n",
    "    fold_train_subset = torch.utils.data.Subset(train_loader.dataset, train_index)\n",
    "    fold_val_subset = torch.utils.data.Subset(val_loader.dataset, val_index)\n",
    "\n",
    "    fold_train_loader = DataLoader(fold_train_subset, batch_size=4, shuffle=True)\n",
    "    fold_val_loader = DataLoader(fold_val_subset, batch_size=4, shuffle=False)\n",
    "\n",
    "\n",
    "    # Instantiate a new model for each fold\n",
    "    model = HybridModel(CNNFeatureExtractor())\n",
    "    model.apply(weights_init)\n",
    "    model.to(device)\n",
    "\n",
    "    # Set up the optimizer, scheduler, and loss function\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    # Train and evaluate the model\n",
    "    # val_loss = train_and_evaluate(model, train_loader, val_loader, optimizer, scheduler, criterion, epochs, device)\n",
    "    val_loss = train_and_evaluate(model, fold_train_loader, fold_val_loader, optimizer, scheduler, criterion, epochs, device)\n",
    "    \n",
    "    # Model evaluation on the validation set\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs_val = []\n",
    "        labels_val = []\n",
    "        for evi_batch, label_batch, time_features_batch in val_loader:\n",
    "            evi_batch, label_batch, time_features_batch = evi_batch.to(device), label_batch.to(device), time_features_batch.to(device)\n",
    "            outputs_batch = model(evi_batch, time_features_batch) # lbs/pixel\n",
    "            outputs_val.extend(outputs_batch.cpu().numpy().flatten())\n",
    "            label_batch = label_batch.unsqueeze(1).unsqueeze(2).expand(-1, target_shape[0], target_shape[1])\n",
    "            labels_val.extend(label_batch.cpu().numpy().flatten())\n",
    "\n",
    "    # Flatten the outputs and labels\n",
    "    outputs_val = np.array(outputs_val)\n",
    "    labels_val = np.array(labels_val)\n",
    "\n",
    "    # Calculate val metrics\n",
    "    mse = mean_squared_error(labels_val, outputs_val)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(labels_val, outputs_val)\n",
    "    r2 = r2_score(labels_val, outputs_val)\n",
    "\n",
    "    mse_scores.append(mse)\n",
    "    rmse_scores.append(rmse)\n",
    "    mae_scores.append(mae)\n",
    "    r2_scores.append(r2)\n",
    "\n",
    "# Print results\n",
    "print(f\"Average MSE: {np.mean(mse_scores)}\")\n",
    "print(f\"Average RMSE: {np.mean(rmse_scores)}\")\n",
    "print(f\"Average MAE: {np.mean(mae_scores)}\")\n",
    "print(f\"Average R-squared: {np.mean(r2_scores)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train on full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of samples - Training   - 510\n",
      "# of samples - Validation - 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/128 [00:00<?, ?it/s]/home/hbar6/projects/MIDS/210/AgriSense-210-Capstone/train_model/inference_utils.py:52: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /home/conda/feedstock_root/build_artifacts/libtorch_1718580740865/work/torch/csrc/utils/tensor_new.cpp:274.)\n",
      "  evi_sequence = torch.tensor(evi_sequence, dtype=torch.float32).unsqueeze(1)\n",
      "100%|██████████| 128/128 [01:03<00:00,  2.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.02303801325973609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hbar6/miniconda3/envs/agrisense-train/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.13716325513087213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [01:00<00:00,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.00021912637054555262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hbar6/miniconda3/envs/agrisense-train/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.13683857419528067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [01:00<00:00,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 4.714069107225605e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hbar6/miniconda3/envs/agrisense-train/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.13679931915248744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [01:00<00:00,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 1.2139776693148585e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hbar6/miniconda3/envs/agrisense-train/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.13678972469642758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [01:00<00:00,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 2.449644118566064e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hbar6/miniconda3/envs/agrisense-train/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.13678752846317366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [01:00<00:00,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss: 7.677901634311471e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hbar6/miniconda3/envs/agrisense-train/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.13678681483725086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [01:00<00:00,  2.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss: 3.032403498042413e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hbar6/miniconda3/envs/agrisense-train/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.13678655843250453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [01:01<00:00,  2.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss: 1.6920563471189976e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hbar6/miniconda3/envs/agrisense-train/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.13678646262269467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [01:00<00:00,  2.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss: 1.0260573640036297e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hbar6/miniconda3/envs/agrisense-train/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.13678642455488443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [01:00<00:00,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss: 5.5787742407435725e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hbar6/miniconda3/envs/agrisense-train/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1367864032217767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [01:00<00:00,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Loss: 2.9276606201833477e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hbar6/miniconda3/envs/agrisense-train/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.13678638232522644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [01:00<00:00,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Loss: 1.2652823795644697e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hbar6/miniconda3/envs/agrisense-train/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1367863641353324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [01:00<00:00,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Loss: 4.771049414917239e-09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hbar6/miniconda3/envs/agrisense-train/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.13678636751137674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [01:00<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Loss: 1.5382479281230571e-09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hbar6/miniconda3/envs/agrisense-train/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.13678635086398572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [01:00<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Loss: 4.786846412416397e-10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hbar6/miniconda3/envs/agrisense-train/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.13678636238910258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [01:00<00:00,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Loss: 1.3792824101279723e-10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hbar6/miniconda3/envs/agrisense-train/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1367863685300108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [01:00<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, Loss: 3.7930990881324296e-11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hbar6/miniconda3/envs/agrisense-train/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1367863482737448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [01:00<00:00,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, Loss: 1.030097532846283e-11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hbar6/miniconda3/envs/agrisense-train/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.13678636791883036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [01:00<00:00,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, Loss: 3.4419171131595274e-12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hbar6/miniconda3/envs/agrisense-train/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1367863736813888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [01:00<00:00,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Loss: 1.862709280804205e-12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hbar6/miniconda3/envs/agrisense-train/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.13678635843098164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [01:00<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21, Loss: 1.5365051628925621e-12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hbar6/miniconda3/envs/agrisense-train/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1367863556370139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [01:00<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22, Loss: 1.483005749043814e-12\n",
      "Validation Loss: 0.1367863569757901\n",
      "Early stopping!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hbar6/miniconda3/envs/agrisense-train/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# Instantiate a new model for each fold\n",
    "model = HybridModel(CNNFeatureExtractor())\n",
    "model.apply(weights_init)\n",
    "model.to(device)\n",
    "\n",
    "# Set up the optimizer, scheduler, and loss function\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Train and evaluate the model\n",
    "val_loss = train_and_evaluate(model, train_loader, val_loader, optimizer, scheduler, criterion, epochs, device)\n",
    "\n",
    "torch.save(model.state_dict(), \"./trained-full-dataset-yield-density-no-leakage.pt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# load in model from file\n",
    "# inf_model_weights = torch.load(\"trained-full-dataset.pt\", weights_only=True)\n",
    "inf_model_weights = torch.load(\"trained-full-dataset-yield-density-no-leakage.pt\", weights_only=True)\n",
    "inf_model = HybridModel(CNNFeatureExtractor())\n",
    "inf_model.load_state_dict(inf_model_weights)\n",
    "inf_model.to(device)\n",
    "inf_model.eval()\n",
    "\n",
    "scaler = joblib.load(\"yield_scaler.save\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# inf_output = inf_model(evi_val, time_features_val)\n",
    "\n",
    "# print(f\"{evi_val.shape = }\")\n",
    "# print(f\"{time_features_val.shape = }\")\n",
    "# print(f\"{inf_output.shape = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2012-03-04 00:00:00')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yield_data_weekly.iloc[0].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed file 1/83 in 4.125449s\n",
      "Processed file 2/83 in 4.246559s\n",
      "Processed file 3/83 in 4.898093s\n",
      "Processed file 4/83 in 4.672359s\n",
      "Processed file 5/83 in 5.460909s\n",
      "Processed file 6/83 in 4.038937s\n",
      "Processed file 7/83 in 3.490030s\n",
      "Processed file 8/83 in 4.127463s\n",
      "Processed file 9/83 in 3.800272s\n",
      "Processed file 10/83 in 3.523895s\n",
      "Processed file 11/83 in 3.932964s\n",
      "Processed file 12/83 in 3.734574s\n",
      "Processed file 13/83 in 4.148887s\n",
      "Processed file 14/83 in 4.548136s\n",
      "Processed file 15/83 in 3.748950s\n",
      "Processed file 16/83 in 3.109021s\n",
      "Processed file 17/83 in 4.015578s\n",
      "Processed file 18/83 in 4.144617s\n",
      "Processed file 19/83 in 3.917441s\n",
      "Processed file 20/83 in 4.372727s\n",
      "Processed file 21/83 in 4.537723s\n",
      "Processed file 22/83 in 3.373776s\n",
      "Processed file 23/83 in 3.701019s\n",
      "Processed file 24/83 in 3.277262s\n",
      "Processed file 25/83 in 3.982489s\n",
      "Processed file 26/83 in 4.063423s\n",
      "Processed file 27/83 in 3.969857s\n",
      "Processed file 28/83 in 3.823087s\n",
      "Processed file 29/83 in 4.417579s\n",
      "Processed file 30/83 in 4.272311s\n",
      "Processed file 31/83 in 4.337449s\n",
      "Processed file 32/83 in 4.655514s\n",
      "Processed file 33/83 in 3.607922s\n",
      "Processed file 34/83 in 3.480821s\n",
      "Processed file 35/83 in 4.332602s\n",
      "Processed file 36/83 in 4.173650s\n",
      "Processed file 37/83 in 4.149103s\n",
      "Processed file 38/83 in 4.681635s\n",
      "Processed file 39/83 in 4.564671s\n",
      "Processed file 40/83 in 4.628916s\n",
      "Processed file 41/83 in 3.935491s\n",
      "Processed file 42/83 in 3.986924s\n",
      "Processed file 43/83 in 4.027990s\n",
      "Processed file 44/83 in 3.643191s\n",
      "Processed file 45/83 in 3.667214s\n",
      "Processed file 46/83 in 4.494608s\n",
      "Processed file 47/83 in 4.388139s\n",
      "Processed file 48/83 in 4.622298s\n",
      "Processed file 49/83 in 4.251509s\n",
      "Processed file 50/83 in 3.831032s\n",
      "Processed file 51/83 in 4.257247s\n",
      "Processed file 52/83 in 4.217634s\n",
      "Processed file 53/83 in 3.946668s\n",
      "Processed file 54/83 in 3.592932s\n",
      "Processed file 55/83 in 3.819616s\n",
      "Processed file 56/83 in 3.317214s\n",
      "Processed file 57/83 in 4.109729s\n",
      "Processed file 58/83 in 4.652054s\n",
      "Processed file 59/83 in 3.799435s\n",
      "Processed file 60/83 in 3.740969s\n",
      "Processed file 61/83 in 3.611767s\n",
      "Processed file 62/83 in 3.998308s\n",
      "Processed file 63/83 in 4.347283s\n",
      "Processed file 64/83 in 5.206402s\n",
      "Processed file 65/83 in 4.994030s\n",
      "Processed file 66/83 in 3.919130s\n",
      "Processed file 67/83 in 4.904674s\n",
      "Processed file 68/83 in 4.146022s\n",
      "Processed file 69/83 in 3.875714s\n",
      "Processed file 70/83 in 3.812580s\n",
      "Processed file 71/83 in 5.082986s\n",
      "Processed file 72/83 in 4.418611s\n",
      "Processed file 73/83 in 4.540192s\n",
      "Processed file 74/83 in 3.940198s\n",
      "Processed file 75/83 in 4.388614s\n",
      "Processed file 76/83 in 3.834744s\n",
      "Processed file 77/83 in 3.839065s\n",
      "Processed file 78/83 in 4.012993s\n",
      "Processed file 79/83 in 4.053501s\n",
      "Processed file 80/83 in 4.285115s\n",
      "Processed file 81/83 in 4.588550s\n",
      "Processed file 82/83 in 3.816462s\n",
      "Processed file 83/83 in 4.741632s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "evi_data_dir = \"./landsat_evi_monterey_masked\"\n",
    "dataset_loader, _, mean, std = prepare_dataset(evi_data_dir, yield_data_weekly, target_shape, augment=True, full=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running inference... 0.62%\r"
     ]
    }
   ],
   "source": [
    "timestamps = torch.Tensor()\n",
    "yield_labels = torch.Tensor()\n",
    "predictions = torch.Tensor()\n",
    "\n",
    "for idx, (inputs, labels, time_features, timestamp) in enumerate(dataset_loader):\n",
    "    print(f\"Running inference... {idx/len(dataset_loader)*100:.2f}%\", end='\\r')\n",
    "    inputs, labels, time_features = inputs.to(device), labels.to(device), time_features.to(device)\n",
    "    outputs = inf_model(inputs, time_features)\n",
    "    summed_outputs = outputs.sum(dim=(1,2))\n",
    "\n",
    "    if idx >0:\n",
    "        break\n",
    "    timestamps = torch.cat((timestamps, timestamp))\n",
    "    yield_labels = torch.cat((yield_labels, labels.to(\"cpu\")))\n",
    "    predictions = torch.cat((predictions, summed_outputs.to(\"cpu\")))\n",
    "\n",
    "    # loss = criterion(outputs, labels)\n",
    "    # val_loss += loss.item()\n",
    "\n",
    "# val_loss /= len(val_loader)\n",
    "# print(f'Validation Loss: {val_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4385, 0.8434, 0.4935, 0.0000])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yield_labels.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[20429036.3072927 ],\n",
       "       [39287413.27969694],\n",
       "       [22990931.39602876],\n",
       "       [       0.        ]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.inverse_transform(yield_labels.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1023663.94],\n",
       "       [1020795.2 ],\n",
       "       [1033442.56],\n",
       "       [ 977205.5 ]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.inverse_transform(predictions.detach().numpy().reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4385, 0.8434, 0.4935, 0.0000])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yield_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Volume (Pounds)</th>\n",
       "      <th>Cumulative Volumne (Pounds)</th>\n",
       "      <th>Pounds/Acre</th>\n",
       "      <th>month_sin</th>\n",
       "      <th>month_cos</th>\n",
       "      <th>day_of_year_sin</th>\n",
       "      <th>day_of_year_cos</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-03-04</th>\n",
       "      <td>0.011286</td>\n",
       "      <td>1785843.0</td>\n",
       "      <td>18.333333</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>6.123234e-17</td>\n",
       "      <td>0.891981</td>\n",
       "      <td>0.452072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-03-11</th>\n",
       "      <td>0.063317</td>\n",
       "      <td>4735377.0</td>\n",
       "      <td>51.666667</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>6.123234e-17</td>\n",
       "      <td>0.939856</td>\n",
       "      <td>0.341571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-03-18</th>\n",
       "      <td>0.102446</td>\n",
       "      <td>9507645.0</td>\n",
       "      <td>83.500000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>6.123234e-17</td>\n",
       "      <td>0.974100</td>\n",
       "      <td>0.226116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-03-25</th>\n",
       "      <td>0.067456</td>\n",
       "      <td>12649959.0</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>6.123234e-17</td>\n",
       "      <td>0.994218</td>\n",
       "      <td>0.107381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-04-01</th>\n",
       "      <td>0.134627</td>\n",
       "      <td>18921357.0</td>\n",
       "      <td>93.857143</td>\n",
       "      <td>8.660254e-01</td>\n",
       "      <td>-5.000000e-01</td>\n",
       "      <td>0.999917</td>\n",
       "      <td>-0.012910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-12</th>\n",
       "      <td>0.767907</td>\n",
       "      <td>682790517.0</td>\n",
       "      <td>305.285714</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "      <td>0.752667</td>\n",
       "      <td>-0.658402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-19</th>\n",
       "      <td>0.787426</td>\n",
       "      <td>682790517.0</td>\n",
       "      <td>365.166667</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "      <td>0.668064</td>\n",
       "      <td>-0.744104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-26</th>\n",
       "      <td>0.827681</td>\n",
       "      <td>682790517.0</td>\n",
       "      <td>329.285714</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "      <td>0.573772</td>\n",
       "      <td>-0.819015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-02</th>\n",
       "      <td>0.796377</td>\n",
       "      <td>682790517.0</td>\n",
       "      <td>316.571429</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>0.471160</td>\n",
       "      <td>-0.882048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-09</th>\n",
       "      <td>0.527337</td>\n",
       "      <td>682790517.0</td>\n",
       "      <td>366.750000</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>0.361714</td>\n",
       "      <td>-0.932289</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>641 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Volume (Pounds)  Cumulative Volumne (Pounds)  Pounds/Acre  \\\n",
       "Date                                                                    \n",
       "2012-03-04         0.011286                    1785843.0    18.333333   \n",
       "2012-03-11         0.063317                    4735377.0    51.666667   \n",
       "2012-03-18         0.102446                    9507645.0    83.500000   \n",
       "2012-03-25         0.067456                   12649959.0    55.000000   \n",
       "2012-04-01         0.134627                   18921357.0    93.857143   \n",
       "...                     ...                          ...          ...   \n",
       "2024-05-12         0.767907                  682790517.0   305.285714   \n",
       "2024-05-19         0.787426                  682790517.0   365.166667   \n",
       "2024-05-26         0.827681                  682790517.0   329.285714   \n",
       "2024-06-02         0.796377                  682790517.0   316.571429   \n",
       "2024-06-09         0.527337                  682790517.0   366.750000   \n",
       "\n",
       "               month_sin     month_cos  day_of_year_sin  day_of_year_cos  \n",
       "Date                                                                      \n",
       "2012-03-04  1.000000e+00  6.123234e-17         0.891981         0.452072  \n",
       "2012-03-11  1.000000e+00  6.123234e-17         0.939856         0.341571  \n",
       "2012-03-18  1.000000e+00  6.123234e-17         0.974100         0.226116  \n",
       "2012-03-25  1.000000e+00  6.123234e-17         0.994218         0.107381  \n",
       "2012-04-01  8.660254e-01 -5.000000e-01         0.999917        -0.012910  \n",
       "...                  ...           ...              ...              ...  \n",
       "2024-05-12  5.000000e-01 -8.660254e-01         0.752667        -0.658402  \n",
       "2024-05-19  5.000000e-01 -8.660254e-01         0.668064        -0.744104  \n",
       "2024-05-26  5.000000e-01 -8.660254e-01         0.573772        -0.819015  \n",
       "2024-06-02  1.224647e-16 -1.000000e+00         0.471160        -0.882048  \n",
       "2024-06-09  1.224647e-16 -1.000000e+00         0.361714        -0.932289  \n",
       "\n",
       "[641 rows x 7 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yield_data_weekly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamps, yield_labels, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yield_data_weekly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df = pd.DataFrame(data={\"timestamp\":timestamps.to_numpy(), \"prediction\":predictions.to_numpy(), \"truth\":yield_labels.to_numpy()})\n",
    "out_df.to_csv(\"out.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
