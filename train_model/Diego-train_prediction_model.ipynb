{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import rasterio\n",
    "from skimage.transform import resize\n",
    "from skimage.transform import rotate\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tqdm import tqdm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from datetime import timedelta\n",
    "from skimage.draw import polygon\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from shapely.geometry import Polygon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Yield Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Volume (Pounds)  Cumulative Volumne (Pounds)  Pounds/Acre\n",
      "Date                                                                 \n",
      "2012-01-02          23400.0                      23400.0          2.0\n",
      "2012-01-03          26064.0                      49464.0          3.0\n",
      "2012-01-04          32382.0                      81846.0          3.0\n",
      "2012-01-05          69804.0                     151650.0          7.0\n",
      "2012-01-06          18000.0                     169650.0          2.0\n",
      "\n",
      "Number of Yield Data Points:  3970\n",
      "\n",
      "Column Names: Index(['Volume (Pounds)', 'Cumulative Volumne (Pounds)', 'Pounds/Acre'], dtype='object')\n",
      "Number of Yield Data Points: 2879\n",
      "Yield data with time features:\n",
      "            Volume (Pounds)  Cumulative Volumne (Pounds)  Pounds/Acre  \\\n",
      "Date                                                                    \n",
      "2012-03-04         525753.0                    1785843.0    18.333333   \n",
      "2012-03-11        2949534.0                    4735377.0    51.666667   \n",
      "2012-03-18        4772268.0                    9507645.0    83.500000   \n",
      "2012-03-25        3142314.0                   12649959.0    55.000000   \n",
      "2012-04-01        6271398.0                   18921357.0    93.857143   \n",
      "\n",
      "            month_sin     month_cos  day_of_year_sin  day_of_year_cos  \n",
      "Date                                                                   \n",
      "2012-03-04   1.000000  6.123234e-17         0.891981         0.452072  \n",
      "2012-03-11   1.000000  6.123234e-17         0.939856         0.341571  \n",
      "2012-03-18   1.000000  6.123234e-17         0.974100         0.226116  \n",
      "2012-03-25   1.000000  6.123234e-17         0.994218         0.107381  \n",
      "2012-04-01   0.866025 -5.000000e-01         0.999917        -0.012910  \n"
     ]
    }
   ],
   "source": [
    "from utils import process_yield_data\n",
    "from pathlib import Path\n",
    "YIELD_DATA_PATH = Path(\"./combined_yield_data.csv\")\n",
    "yield_data_weekly = process_yield_data(YIELD_DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "target_shape = (512, 512)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNFeatureExtractor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNFeatureExtractor, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.conv4 = nn.Conv2d(128, 256, 3, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(256)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.flattened_size = self._get_conv_output((1, *target_shape))\n",
    "        self.fc1 = nn.Linear(self.flattened_size, 512)\n",
    "\n",
    "    def _get_conv_output(self, shape):\n",
    "        x = torch.rand(1, *shape)\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
    "        x = self.pool(F.relu(self.bn4(self.conv4(x))))\n",
    "        n_size = x.view(1, -1).size(1)\n",
    "        return n_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
    "        x = self.pool(F.relu(self.bn4(self.conv4(x))))\n",
    "        x = self.dropout(x)\n",
    "        x = x.view(-1, self.flattened_size)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return x\n",
    "    \n",
    "class HybridModel(nn.Module):\n",
    "    def __init__(self, cnn_feature_extractor, lstm_hidden_size=64, lstm_layers=1):\n",
    "        super(HybridModel, self).__init__()\n",
    "        self.cnn = cnn_feature_extractor\n",
    "        self.lstm = nn.LSTM(input_size=512, hidden_size=lstm_hidden_size, num_layers=lstm_layers, batch_first=True)\n",
    "        self.fc1 = nn.Linear(lstm_hidden_size + 6, 64)\n",
    "        self.fc2 = nn.Linear(64, target_shape[0] * target_shape[1])  # Predict a value per pixel\n",
    "        self.target_shape = target_shape\n",
    "\n",
    "    def forward(self, x, time_features):\n",
    "        batch_size, time_steps, C, H, W = x.size()\n",
    "        c_in = x.view(batch_size * time_steps, C, H, W)\n",
    "        c_out = self.cnn(c_in)\n",
    "        r_in = c_out.view(batch_size, time_steps, -1)\n",
    "        r_out, (h_n, c_n) = self.lstm(r_in)\n",
    "        r_out = r_out[:, -1, :]\n",
    "        x = torch.cat((r_out, time_features), dim=1)  # Concatenate LSTM output with time features\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        x = x.view(batch_size, *self.target_shape)  # Reshape to the target shape\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "        nn.init.kaiming_normal_(m.weight)\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "\n",
    "# Instantiate model with weight decay regularization\n",
    "cnn_feature_extractor = CNNFeatureExtractor()\n",
    "model = HybridModel(cnn_feature_extractor)\n",
    "model.apply(weights_init)\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training loop with early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_loss = float('inf')\n",
    "patience = 3\n",
    "trigger_times = 0\n",
    "epochs = 50\n",
    "\n",
    "# for epoch in range(epochs):\n",
    "#     running_loss = 0.0\n",
    "#     model.train()\n",
    "#     for i, (inputs, labels, time_features) in enumerate(tqdm(train_loader)):\n",
    "#         if device != \"cpu\":\n",
    "#             inputs, labels, time_features = inputs.to(device), labels.to(device), time_features.to(device)\n",
    "#         optimizer.zero_grad()\n",
    "#         outputs = model(inputs, time_features)\n",
    "#         labels = labels.unsqueeze(1).unsqueeze(2).expand(-1, target_shape[0], target_shape[1])\n",
    "#         loss = criterion(outputs, labels)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         running_loss += loss.item()\n",
    "#     epoch_loss = running_loss / len(train_loader)\n",
    "#     scheduler.step()\n",
    "#     print(f'Epoch {epoch+1}, Loss: {epoch_loss}')\n",
    "\n",
    "#     # Early stopping\n",
    "#     if epoch_loss < best_loss:\n",
    "#         best_loss = epoch_loss\n",
    "#         trigger_times = 0\n",
    "#         torch.save(model.state_dict(), 'best_hybrid_model.pth')  # Save best model\n",
    "#     else:\n",
    "#         trigger_times += 1\n",
    "#         if trigger_times >= patience:\n",
    "#             print(\"Early stopping!\")\n",
    "#             break\n",
    "\n",
    "\n",
    "# def train_model(model, optimizer, scheduler, criterion, train_loader, val_loader, epochs, device, patience=3):\n",
    "#     best_loss = float('inf')\n",
    "#     trigger_times = 0\n",
    "    \n",
    "#     for epoch in range(epochs):\n",
    "#         model.train()\n",
    "#         running_loss = 0.0\n",
    "#         for inputs, labels, time_features in tqdm(train_loader):\n",
    "#             inputs, labels, time_features = inputs.to(device), labels.to(device), time_features.to(device)\n",
    "#             optimizer.zero_grad()\n",
    "#             outputs = model(inputs, time_features)\n",
    "#             labels_expanded = labels.unsqueeze(1).unsqueeze(2).expand(-1, target_shape[0], target_shape[1])\n",
    "#             loss = criterion(outputs, labels_expanded)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "#             running_loss += loss.item()\n",
    "        \n",
    "#         epoch_loss = running_loss / len(train_loader)\n",
    "#         scheduler.step()\n",
    "        \n",
    "#         val_loss = 0.0\n",
    "#         model.eval()\n",
    "#         with torch.no_grad():\n",
    "#             for inputs, labels, time_features in val_loader:\n",
    "#                 inputs, labels, time_features = inputs.to(device), labels.to(device), time_features.to(device)\n",
    "#                 outputs = model(inputs, time_features)\n",
    "#                 labels_expanded = labels.unsqueeze(1).unsqueeze(2).expand(-1, target_shape[0], target_shape[1])\n",
    "#                 loss = criterion(outputs, labels_expanded)\n",
    "#                 val_loss += loss.item()\n",
    "        \n",
    "#         val_loss /= len(val_loader)\n",
    "#         print(f'Epoch {epoch+1}, Training Loss: {epoch_loss}, Validation Loss: {val_loss}')\n",
    "        \n",
    "#         # Early stopping\n",
    "#         if val_loss < best_loss:\n",
    "#             best_loss = val_loss\n",
    "#             trigger_times = 0\n",
    "#             torch.save(model.state_dict(), 'best_hybrid_model.pth')  # Save best model\n",
    "#         else:\n",
    "#             trigger_times += 1\n",
    "#             if trigger_times >= patience:\n",
    "#                 print(\"Early stopping!\")\n",
    "#                 break\n",
    "\n",
    "# # Training and validation\n",
    "# # model = HybridModel(CNNFeatureExtractor()).to(device)\n",
    "# # criterion = nn.MSELoss()\n",
    "# # optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "# # scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "# # train_model(model, optimizer, scheduler, criterion, train_loader, val_loader, epochs=50, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DIEGO: is everything above out-of-date and only the functions below are relevant?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inference_utils import (\n",
    "    preprocess_image,\n",
    "    compute_mean_std,\n",
    "    load_evi_data_and_prepare_features,\n",
    "    find_closest_date,\n",
    "    find_closest_date_in_df,\n",
    "    mask_evi_data,\n",
    "    predict,\n",
    "    predict_weekly_yield\n",
    ")\n",
    "\n",
    "\n",
    "evi_data_dir = \"./landsat_evi_monterey_masked\"\n",
    "evi_data_dict, time_features, mean, std  = load_evi_data_and_prepare_features(evi_data_dir, time_index=yield_data_weekly.index, target_shape=target_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #TODO: Convert the pixel area to physical area (may require a dynamic conversion factor depending on the zoom from the UI)\n",
    "# #TODO: Pass the target date (for prediction) from the UI to this script\n",
    "                                                                                                                                                                                            \n",
    "# # Example polygon coordinates (we need to replace these with actual coordinates from your UI) - this one is just a box\n",
    "# polygon_coords = np.array([\n",
    "#     [100, 100],\n",
    "#     [100, 200],\n",
    "#     [200, 200],\n",
    "#     [200, 100],\n",
    "#     [100, 100]\n",
    "# ])\n",
    "\n",
    "# # Calculate the area based on the polygon coordinates\n",
    "# polygon = Polygon(polygon_coords)\n",
    "# polygon_area = polygon.area \n",
    "\n",
    "# # Convert polygon area from pixel units to acres (using the LandSat Conversion Factor)\n",
    "# conversion_factor = 30  # 1 pixel = 30m^2\n",
    "# polygon_area_acres = polygon_area * conversion_factor\n",
    "\n",
    "# # Start date for predictions\n",
    "# start_date = pd.to_datetime(\"2022-07-01\") # This is an example date; we need to take this from the UI\n",
    "\n",
    "# # Load and preprocess the EVI data\n",
    "# time_index = yield_data_weekly.index\n",
    "# evi_data_dict, time_features_list, mean, std = load_evi_data_and_prepare_features(evi_data_dir, time_index, target_shape)\n",
    "\n",
    "# # Generate weekly predictions\n",
    "# dates, predicted_yields = predict_weekly_yield(evi_data_dict, yield_data_weekly, start_date, polygon_area_acres, mean, std, target_shape, model, device)\n",
    "\n",
    "# # Convert predictions to a numpy array\n",
    "# predicted_yields = np.array(predicted_yields).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot the predicted yields as a trend line\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.plot(dates, predicted_yields, marker='o', linestyle='-', color='b')\n",
    "# plt.xlabel('Date')\n",
    "# plt.ylabel('Predicted Yield (Pounds)')\n",
    "# plt.title(f'Predicted Weekly Yield for Selected Polygon Area (Starting {start_date})')\n",
    "# plt.grid(True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation (Basic Evaluation Metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function to evaluate the model on the test set\n",
    "# def evaluate_model(model, test_loader, mean, std, target_shape, device):\n",
    "#     model.eval()\n",
    "#     all_true = []\n",
    "#     all_pred = []\n",
    "    \n",
    "#     with torch.no_grad():\n",
    "#         for inputs, labels, time_features in test_loader:\n",
    "#             if device != \"cpu\":\n",
    "#                 inputs, labels, time_features = inputs.to(device), labels.to(device), time_features.to(device)\n",
    "            \n",
    "#             outputs = model(inputs, time_features)\n",
    "#             labels = labels.unsqueeze(1).unsqueeze(2).expand(-1, target_shape[0], target_shape[1])\n",
    "            \n",
    "#             all_true.append(labels.cpu().numpy())\n",
    "#             all_pred.append(outputs.cpu().numpy())\n",
    "    \n",
    "#     all_true = np.concatenate(all_true).flatten()\n",
    "#     all_pred = np.concatenate(all_pred).flatten()\n",
    "    \n",
    "#     mse = mean_squared_error(all_true, all_pred)\n",
    "#     rmse = np.sqrt(mse)\n",
    "#     mae = mean_absolute_error(all_true, all_pred)\n",
    "#     r2 = r2_score(all_true, all_pred)\n",
    "    \n",
    "#     return mse, rmse, mae, r2\n",
    "\n",
    "# # Evaluate the model on the test set\n",
    "# mse, rmse, mae, r2 = evaluate_model(model, test_loader, mean, std, target_shape, device)\n",
    "\n",
    "# print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "# print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "# print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "# print(f\"R-squared (R²): {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation (Cross Validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "       Train Index = 0, ..., 110 len=111\n",
      "       Valid Index = 111, ..., 216 len=106\n",
      "       Train Dates = 2014-02-23 00:00:00, ..., 2014-02-23 00:00:00 len=1\n",
      "       Valid Dates = 2016-04-17 00:00:00, ..., 2016-04-17 00:00:00 len=1\n",
      "  (get)Train Index = 103, ..., 103 len=1\n",
      "  (get)Valid Index = 215, ..., 215 len=1\n",
      "  evi_train.shape  = (1, 512, 512)\n",
      "  evi_val.shape    = (1, 512, 512)\n",
      "  time_features_train.shape  = (1, 6)\n",
      "  time_features_val.shape    = (1, 6)\n",
      "  labels_train.shape  = (1,)\n",
      "  labels_val.shape    = (1,)\n",
      "  (torch)evi_train.shape  = torch.Size([1, 1, 1, 512, 512])\n",
      "  (torch)evi_val.shape    = torch.Size([1, 1, 1, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 20.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.13545666635036469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 24.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.1347959339618683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 23.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 0.11724184453487396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 23.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 0.07898657023906708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 22.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 0.08247167617082596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 22.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss: 0.06390894949436188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 23.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss: 0.05569910630583763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 21.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss: 0.056405600160360336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 22.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss: 0.053138814866542816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 22.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss: 0.049059562385082245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 22.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Loss: 0.04412923380732536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 22.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Loss: 0.04986071586608887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 22.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Loss: 0.04482012614607811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 22.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Loss: 0.04446239769458771\n",
      "Early stopping!\n",
      "Validation Loss: 0.2333991825580597\n",
      "Fold 2\n",
      "       Train Index = 0, ..., 216 len=217\n",
      "       Valid Index = 217, ..., 322 len=106\n",
      "       Train Dates = 2014-02-23 00:00:00, ..., 2016-04-17 00:00:00 len=2\n",
      "       Valid Dates = 2017-10-29 00:00:00, ..., 2017-10-29 00:00:00 len=1\n",
      "  (get)Train Index = 103, ..., 215 len=2\n",
      "  (get)Valid Index = 295, ..., 295 len=1\n",
      "  evi_train.shape  = (2, 512, 512)\n",
      "  evi_val.shape    = (1, 512, 512)\n",
      "  time_features_train.shape  = (2, 6)\n",
      "  time_features_val.shape    = (1, 6)\n",
      "  labels_train.shape  = (2,)\n",
      "  labels_val.shape    = (1,)\n",
      "  (torch)evi_train.shape  = torch.Size([2, 1, 1, 512, 512])\n",
      "  (torch)evi_val.shape    = torch.Size([1, 1, 1, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 16.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.22057074308395386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 17.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.28075557947158813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 18.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 0.2492993175983429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 19.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 0.2151544839143753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 19.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 0.19372932612895966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 19.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss: 0.17846587300300598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 20.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss: 0.19508683681488037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 19.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss: 0.1731199026107788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 18.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss: 0.17069417238235474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 17.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss: 0.1625077873468399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 19.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Loss: 0.16995501518249512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 19.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Loss: 0.16934813559055328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 18.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Loss: 0.1687334030866623\n",
      "Early stopping!\n",
      "Validation Loss: 0.1641451120376587\n",
      "Fold 3\n",
      "       Train Index = 0, ..., 322 len=323\n",
      "       Valid Index = 323, ..., 428 len=106\n",
      "       Train Dates = 2014-02-23 00:00:00, ..., 2017-10-29 00:00:00 len=3\n",
      "       Valid Dates = 2020-04-12 00:00:00, ..., 2020-04-12 00:00:00 len=1\n",
      "  (get)Train Index = 103, ..., 295 len=3\n",
      "  (get)Valid Index = 423, ..., 423 len=1\n",
      "  evi_train.shape  = (3, 512, 512)\n",
      "  evi_val.shape    = (1, 512, 512)\n",
      "  time_features_train.shape  = (3, 6)\n",
      "  time_features_val.shape    = (1, 6)\n",
      "  labels_train.shape  = (3,)\n",
      "  labels_val.shape    = (1,)\n",
      "  (torch)evi_train.shape  = torch.Size([3, 1, 1, 512, 512])\n",
      "  (torch)evi_val.shape    = torch.Size([1, 1, 1, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 21.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.2611491531133652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 23.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.2090604528784752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 23.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 0.13958044722676277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 23.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 0.137933898717165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 23.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 0.14423464238643646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 23.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss: 0.11506232991814613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 23.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss: 0.08873882796615362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 22.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss: 0.08751200418919325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 23.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss: 0.08396967872977257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 23.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss: 0.09809453040361404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 23.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Loss: 0.11677070148289204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 23.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Loss: 0.09645003080368042\n",
      "Early stopping!\n",
      "Validation Loss: 0.08816248178482056\n",
      "Fold 4\n",
      "       Train Index = 0, ..., 428 len=429\n",
      "       Valid Index = 429, ..., 534 len=106\n",
      "       Train Dates = 2014-02-23 00:00:00, ..., 2020-04-12 00:00:00 len=4\n",
      "       Valid Dates = 2022-04-10 00:00:00, ..., 2022-04-10 00:00:00 len=1\n",
      "  (get)Train Index = 103, ..., 423 len=4\n",
      "  (get)Valid Index = 527, ..., 527 len=1\n",
      "  evi_train.shape  = (4, 512, 512)\n",
      "  evi_val.shape    = (1, 512, 512)\n",
      "  time_features_train.shape  = (4, 6)\n",
      "  time_features_val.shape    = (1, 6)\n",
      "  labels_train.shape  = (4,)\n",
      "  labels_val.shape    = (1,)\n",
      "  (torch)evi_train.shape  = torch.Size([4, 1, 1, 512, 512])\n",
      "  (torch)evi_val.shape    = torch.Size([1, 1, 1, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 20.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.269936241209507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 21.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.19428962469100952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 21.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 0.16696243733167648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 22.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 0.1566290333867073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 22.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 0.1483641043305397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 21.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss: 0.12761667370796204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 21.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss: 0.1265462264418602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 21.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss: 0.1067146398127079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 21.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss: 0.09925145283341408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 21.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss: 0.0929182767868042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 22.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Loss: 0.08851020783185959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 21.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Loss: 0.08798372000455856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 21.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Loss: 0.08747614920139313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 21.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Loss: 0.08700060658156872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 21.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Loss: 0.08650781214237213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 22.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Loss: 0.08600451052188873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 21.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, Loss: 0.0855204425752163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 21.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, Loss: 0.0850878581404686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 21.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, Loss: 0.08462583646178246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 21.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Loss: 0.084206223487854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 21.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21, Loss: 0.08387266099452972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 21.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22, Loss: 0.08382625877857208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 21.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23, Loss: 0.08378421887755394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 21.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24, Loss: 0.08374135196208954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 21.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25, Loss: 0.08369696885347366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 21.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26, Loss: 0.08365502208471298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 21.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27, Loss: 0.083614531904459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 21.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28, Loss: 0.08357258886098862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 21.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29, Loss: 0.08352800086140633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 21.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30, Loss: 0.08348583057522774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 21.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31, Loss: 0.08345488458871841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 20.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32, Loss: 0.08345091342926025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 20.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33, Loss: 0.08344615623354912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 21.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34, Loss: 0.08344200626015663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 21.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35, Loss: 0.08343765884637833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 22.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36, Loss: 0.08343352377414703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 21.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37, Loss: 0.08342905715107918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 21.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38, Loss: 0.08342474699020386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 21.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39, Loss: 0.08342060260474682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 21.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40, Loss: 0.08341631852090359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 21.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41, Loss: 0.08341292664408684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 21.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42, Loss: 0.08341247960925102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 21.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43, Loss: 0.08341202139854431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 21.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44, Loss: 0.08341162092983723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 21.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45, Loss: 0.08341103419661522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 21.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46, Loss: 0.08341065049171448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 22.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47, Loss: 0.08341028913855553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 21.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48, Loss: 0.08340977132320404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 21.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49, Loss: 0.08340926468372345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 22.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Loss: 0.08340897969901562\n",
      "Validation Loss: 0.248135045170784\n",
      "Fold 5\n",
      "       Train Index = 0, ..., 534 len=535\n",
      "       Valid Index = 535, ..., 640 len=106\n",
      "       Train Dates = 2014-02-23 00:00:00, ..., 2022-04-10 00:00:00 len=5\n",
      "       Valid Dates = 2022-07-31 00:00:00, ..., 2023-12-17 00:00:00 len=8\n",
      "  (get)Train Index = 103, ..., 527 len=5\n",
      "  (get)Valid Index = 543, ..., 615 len=8\n",
      "  evi_train.shape  = (5, 512, 512)\n",
      "  evi_val.shape    = (8, 512, 512)\n",
      "  time_features_train.shape  = (5, 6)\n",
      "  time_features_val.shape    = (8, 6)\n",
      "  labels_train.shape  = (5,)\n",
      "  labels_val.shape    = (8,)\n",
      "  (torch)evi_train.shape  = torch.Size([5, 1, 1, 512, 512])\n",
      "  (torch)evi_val.shape    = torch.Size([8, 1, 1, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 22.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.16929728537797928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 23.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.17360803236564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 23.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 0.17965763062238693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 23.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 0.14718342572450638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 23.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 0.13779729108015695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 23.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss: 0.12136135001977284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 23.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss: 0.11471111327409744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 23.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss: 0.10664999485015869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 23.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss: 0.12894625589251518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 23.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss: 0.09851867457230885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 23.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Loss: 0.09437990933656693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 23.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Loss: 0.10975918422142665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 23.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Loss: 0.09370982026060422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 23.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Loss: 0.0944518509010474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 23.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Loss: 0.09313013901313145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 23.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Loss: 0.08456646542375286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 23.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, Loss: 0.08431454251209895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 23.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, Loss: 0.09234229226907094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 23.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, Loss: 0.10780388365189235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 23.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Loss: 0.10758685568968455\n",
      "Early stopping!\n",
      "Validation Loss: 0.14833451341837645\n",
      "Average MSE: 0.17643526196479797\n",
      "Average RMSE: 0.41369152069091797\n",
      "Average MAE: 0.3471130132675171\n",
      "Average R-squared: -39942233052372.36\n"
     ]
    }
   ],
   "source": [
    "# Cross-validation\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "mse_scores = []\n",
    "rmse_scores = []\n",
    "mae_scores = []\n",
    "r2_scores = []\n",
    "\n",
    "def train_and_evaluate(model, train_loader, val_loader, optimizer, scheduler, criterion, epochs, device):\n",
    "    best_loss = float('inf')\n",
    "    patience = 3\n",
    "    trigger_times = 0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        model.train()\n",
    "        for inputs, labels, time_features in tqdm(train_loader):\n",
    "            inputs, labels, time_features = inputs.to(device), labels.to(device), time_features.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs, time_features)\n",
    "            labels = labels.unsqueeze(1).unsqueeze(2).expand(-1, target_shape[0], target_shape[1])\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        scheduler.step()\n",
    "        print(f'Epoch {epoch + 1}, Loss: {epoch_loss}')\n",
    "\n",
    "        # Early stopping\n",
    "        if epoch_loss < best_loss:\n",
    "            best_loss = epoch_loss\n",
    "            trigger_times = 0\n",
    "        else:\n",
    "            trigger_times += 1\n",
    "            if trigger_times >= patience:\n",
    "                print(\"Early stopping!\")\n",
    "                break\n",
    "\n",
    "    # Evaluate on validation set\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels, time_features in val_loader:\n",
    "            inputs, labels, time_features = inputs.to(device), labels.to(device), time_features.to(device)\n",
    "            outputs = model(inputs, time_features)\n",
    "            labels = labels.unsqueeze(1).unsqueeze(2).expand(-1, target_shape[0], target_shape[1])\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "    \n",
    "    val_loss /= len(val_loader)\n",
    "    print(f'Validation Loss: {val_loss}')\n",
    "    return val_loss\n",
    "\n",
    "for fold, (train_index, val_index) in enumerate(tscv.split(yield_data_weekly)):\n",
    "    print(f\"Fold {fold + 1}\")\n",
    "    print(f\"       Train Index = {train_index[0]}, ..., {train_index[-1]} len={len(train_index)}\")\n",
    "    print(f\"       Valid Index = {val_index[0]}, ..., {val_index[-1]} len={len(val_index)}\")\n",
    "\n",
    "    train_dates = yield_data_weekly.index[train_index].intersection(evi_data_dict.keys())\n",
    "    val_dates = yield_data_weekly.index[val_index].intersection(evi_data_dict.keys())\n",
    "    print(f\"       Train Dates = {train_dates[0]}, ..., {train_dates[-1]} len={len(train_dates)}\")\n",
    "    print(f\"       Valid Dates = {val_dates[0]}, ..., {val_dates[-1]} len={len(val_dates)}\")\n",
    "\n",
    "    train_index = yield_data_weekly.index.get_indexer(train_dates)\n",
    "    val_index = yield_data_weekly.index.get_indexer(val_dates)\n",
    "    print(f\"  (get)Train Index = {train_index[0]}, ..., {train_index[-1]} len={len(train_index)}\")\n",
    "    print(f\"  (get)Valid Index = {val_index[0]}, ..., {val_index[-1]} len={len(val_index)}\")\n",
    "\n",
    "    evi_train = np.array([evi_data_dict[date] for date in train_dates])\n",
    "    evi_val = np.array([evi_data_dict[date] for date in val_dates])\n",
    "    print(f\"  evi_train.shape  = {evi_train.shape}\")\n",
    "    print(f\"  evi_val.shape    = {evi_val.shape}\")\n",
    "\n",
    "    time_features_train = yield_data_weekly.loc[train_dates][['month_sin', 'month_cos', 'day_of_year_sin', 'day_of_year_cos', 'Volume (Pounds)', 'Cumulative Volumne (Pounds)']].values\n",
    "    time_features_val = yield_data_weekly.loc[val_dates][['month_sin', 'month_cos', 'day_of_year_sin', 'day_of_year_cos', 'Volume (Pounds)', 'Cumulative Volumne (Pounds)']].values\n",
    "    print(f\"  time_features_train.shape  = {time_features_train.shape}\")\n",
    "    print(f\"  time_features_val.shape    = {time_features_val.shape}\")\n",
    "    labels_train = yield_data_weekly.loc[train_dates]['Volume (Pounds)'].values\n",
    "    labels_val = yield_data_weekly.loc[val_dates]['Volume (Pounds)'].values\n",
    "    print(f\"  labels_train.shape  = {labels_train.shape}\")\n",
    "    print(f\"  labels_val.shape    = {labels_val.shape}\")\n",
    "\n",
    "    evi_train = torch.tensor(evi_train, dtype=torch.float32).unsqueeze(1).unsqueeze(2).to(device)\n",
    "    evi_val = torch.tensor(evi_val, dtype=torch.float32).unsqueeze(1).unsqueeze(2).to(device)\n",
    "    print(f\"  (torch)evi_train.shape  = {evi_train.shape}\")\n",
    "    print(f\"  (torch)evi_val.shape    = {evi_val.shape}\")\n",
    "    time_features_train = torch.tensor(time_features_train, dtype=torch.float32).to(device)\n",
    "    time_features_val = torch.tensor(time_features_val, dtype=torch.float32).to(device)\n",
    "    labels_train = torch.tensor(labels_train, dtype=torch.float32).to(device)\n",
    "    labels_val = torch.tensor(labels_val, dtype=torch.float32).to(device)\n",
    "\n",
    "    train_loader = DataLoader(list(zip(evi_train, labels_train, time_features_train)), batch_size=2, shuffle=True)\n",
    "    val_loader = DataLoader(list(zip(evi_val, labels_val, time_features_val)), batch_size=2, shuffle=False)\n",
    "\n",
    "    model = HybridModel(CNNFeatureExtractor())\n",
    "    model.apply(weights_init)\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    val_loss = train_and_evaluate(model, train_loader, val_loader, optimizer, scheduler, criterion, epochs, device)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs_val = model(evi_val, time_features_val)\n",
    "\n",
    "    outputs_val_flat = outputs_val.cpu().numpy().flatten()\n",
    "    labels_val_expanded = labels_val.unsqueeze(1).unsqueeze(2).expand(-1, target_shape[0], target_shape[1])\n",
    "    labels_val_flat = labels_val_expanded.cpu().numpy().flatten()\n",
    "\n",
    "    mse = mean_squared_error(labels_val_flat, outputs_val_flat)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(labels_val_flat, outputs_val_flat)\n",
    "    r2 = r2_score(labels_val_flat, outputs_val_flat)\n",
    "\n",
    "    mse_scores.append(mse)\n",
    "    rmse_scores.append(rmse)\n",
    "    mae_scores.append(mae)\n",
    "    r2_scores.append(r2)\n",
    "\n",
    "print(f\"Average MSE: {np.mean(mse_scores)}\")\n",
    "print(f\"Average RMSE: {np.mean(rmse_scores)}\")\n",
    "print(f\"Average MAE: {np.mean(mae_scores)}\")\n",
    "print(f\"Average R-squared: {np.mean(r2_scores)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model to file\n",
    "torch.save(model.state_dict(), \"diego-bad-model.pt\")\n",
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evi_val.shape = torch.Size([8, 1, 1, 512, 512])\n",
      "time_features_val.shape = torch.Size([8, 6])\n",
      "inf_output.shape = torch.Size([8, 512, 512])\n"
     ]
    }
   ],
   "source": [
    "# load in model from file\n",
    "inf_model_weights = torch.load(\"diego-bad-model.pt\", weights_only=True)\n",
    "inf_model = HybridModel(CNNFeatureExtractor())\n",
    "inf_model.load_state_dict(inf_model_weights)\n",
    "inf_model.to(device)\n",
    "inf_model.eval()\n",
    "inf_output = inf_model(evi_val, time_features_val)\n",
    "\n",
    "print(f\"{evi_val.shape = }\")\n",
    "print(f\"{time_features_val.shape = }\")\n",
    "print(f\"{inf_output.shape = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the shapes above? Specifically the input?\n",
    "\n",
    "[8, 1, 1, 512, 512]\n",
    "\n",
    "[n_samples, ?, ?, width, height]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# define the model \n",
    "model = HybridModel(CNNFeatureExtractor())\n",
    "model.apply(weights_init)\n",
    "model.to(device)\n",
    "\n",
    "# define training criteria\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_train_samples(576) + n_val_samples(65) == len(yield_weekly_data)(641) = True\n"
     ]
    }
   ],
   "source": [
    "# create full datasets for training\n",
    "# make validation a lil bit smaller so we get a \"better\" model for inference?\n",
    "\n",
    "# make our own train_index and val_index for now\n",
    "n_train_samples = int(len(yield_data_weekly) * 0.9)\n",
    "n_val_samples = len(yield_data_weekly) - n_train_samples\n",
    "indices = np.arange(0, len(yield_data_weekly), 1, dtype=int)\n",
    "train_index = indices[0:n_train_samples]\n",
    "val_index = indices[n_train_samples:]\n",
    "print(f\"n_train_samples({len(train_index)}) + n_val_samples({len(val_index)}) == len(yield_weekly_data)({len(yield_data_weekly)}) = {len(train_index)+len(val_index) == len(yield_data_weekly)}\")\n",
    "\n",
    "\n",
    "# print(f\"Train Indexes = {train_index}\")\n",
    "# print(f\"Valid Indexes = {val_index}\")\n",
    "\n",
    "train_dates = yield_data_weekly.index[train_index].intersection(evi_data_dict.keys())\n",
    "# val_dates = yield_data_weekly.index[val_index].intersection(evi_data_dict.keys())\n",
    "# print(f\"       Train Dates = {train_dates[0]}, ..., {train_dates[-1]} len={len(train_dates)}\")\n",
    "# print(f\"       Valid Dates = {val_dates[0]}, ..., {val_dates[-1]} len={len(val_dates)}\")\n",
    "\n",
    "# train_index = yield_data_weekly.index.get_indexer(train_dates)\n",
    "# val_index = yield_data_weekly.index.get_indexer(val_dates)\n",
    "# print(f\"  (get)Train Index = {train_index[0]}, ..., {train_index[-1]} len={len(train_index)}\")\n",
    "# print(f\"  (get)Valid Index = {val_index[0]}, ..., {val_index[-1]} len={len(val_index)}\")\n",
    "\n",
    "# evi_train = np.array([evi_data_dict[date] for date in train_dates])\n",
    "# evi_val = np.array([evi_data_dict[date] for date in val_dates])\n",
    "# print(f\"  evi_train.shape  = {evi_train.shape}\")\n",
    "# print(f\"  evi_val.shape    = {evi_val.shape}\")\n",
    "\n",
    "# time_features_train = yield_data_weekly.loc[train_dates][['month_sin', 'month_cos', 'day_of_year_sin', 'day_of_year_cos', 'Volume (Pounds)', 'Cumulative Volumne (Pounds)']].values\n",
    "# time_features_val = yield_data_weekly.loc[val_dates][['month_sin', 'month_cos', 'day_of_year_sin', 'day_of_year_cos', 'Volume (Pounds)', 'Cumulative Volumne (Pounds)']].values\n",
    "# labels_train = yield_data_weekly.loc[train_dates]['Volume (Pounds)'].values\n",
    "# labels_val = yield_data_weekly.loc[val_dates]['Volume (Pounds)'].values\n",
    "\n",
    "# evi_train = torch.tensor(evi_train, dtype=torch.float32).unsqueeze(1).unsqueeze(2).to(device)\n",
    "# time_features_train = torch.tensor(time_features_train, dtype=torch.float32).to(device)\n",
    "# time_features_val = torch.tensor(time_features_val, dtype=torch.float32).to(device)\n",
    "# labels_train = torch.tensor(labels_train, dtype=torch.float32).to(device)\n",
    "# labels_val = torch.tensor(labels_val, dtype=torch.float32).to(device)\n",
    "\n",
    "# train_loader = DataLoader(list(zip(evi_train, labels_train, time_features_train)), batch_size=2, shuffle=True)\n",
    "# val_loader = DataLoader(list(zip(evi_val, labels_val, time_features_val)), batch_size=2, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([Timestamp('2014-02-23 00:00:00'), Timestamp('2016-04-17 00:00:00'), Timestamp('2017-10-29 00:00:00'), Timestamp('2020-04-12 00:00:00'), Timestamp('2022-04-10 00:00:00'), Timestamp('2022-07-31 00:00:00'), Timestamp('2022-09-25 00:00:00'), Timestamp('2022-11-20 00:00:00'), Timestamp('2023-03-12 00:00:00'), Timestamp('2023-05-07 00:00:00'), Timestamp('2023-07-02 00:00:00'), Timestamp('2023-10-22 00:00:00'), Timestamp('2023-12-17 00:00:00')])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evi_data_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2012-03-04', '2012-03-11', '2012-03-18', '2012-03-25',\n",
       "               '2012-04-01', '2012-04-08', '2012-04-15', '2012-04-22',\n",
       "               '2012-04-29', '2012-05-06',\n",
       "               ...\n",
       "               '2023-01-08', '2023-01-15', '2023-01-22', '2023-01-29',\n",
       "               '2023-02-05', '2023-02-12', '2023-02-19', '2023-02-26',\n",
       "               '2023-03-05', '2023-03-12'],\n",
       "              dtype='datetime64[ns]', name='Date', length=576, freq=None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yield_data_weekly.index[train_index]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
